{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db0f208a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 转置卷积\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f39b5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:22.451701Z",
     "iopub.status.busy": "2023-08-18T07:05:22.451411Z",
     "iopub.status.idle": "2023-08-18T07:05:24.490785Z",
     "shell.execute_reply": "2023-08-18T07:05:24.489970Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a83f3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "实现基本的转置卷积运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d911e2",
   "metadata": {},
   "source": [
    "输入 X:<br>\n",
    "[1 2]<br>\n",
    "[3 4]<br>\n",
    "卷积核 K:<br>\n",
    "[1 0]<br>\n",
    "[0 1]<br>\n",
    "输出 Y (3×3):<br>\n",
    "[1 2 0]<br>\n",
    "[3 4 2]<br>\n",
    "[0 3 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e15ba3",
   "metadata": {},
   "source": [
    "计算过程：<br>\n",
    "X[0,0]=1 → 在Y的(0,0)位置叠加 1*K<br>\n",
    "X[0,1]=2 → 在Y的(0,1)位置叠加 2*K<br>\n",
    "X[1,0]=3 → 在Y的(1,0)位置叠加 3*K<br>\n",
    "X[1,1]=4 → 在Y的(1,1)位置叠加 4*K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c46118",
   "metadata": {},
   "source": [
    "| 部分                      | 含义                                        |\n",
    "| ----------------------- | ----------------------------------------- |\n",
    "| `X[i, j]`               | 输入矩阵中的一个**标量值**（单个数字）                     |\n",
    "| `X[i, j] * K`           | 把这个数字乘以卷积核 `K` 的**每个元素**（广播机制）            |\n",
    "| `Y[i: i + h, j: j + w]` | 输出矩阵 `Y` 中，从 `(i, j)` 开始、大小为 `h × w` 的子区域 |\n",
    "| `+=`                    | **累加**到该子区域（不是覆盖，是相加）                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6931d90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:24.494981Z",
     "iopub.status.busy": "2023-08-18T07:05:24.494307Z",
     "iopub.status.idle": "2023-08-18T07:05:24.499745Z",
     "shell.execute_reply": "2023-08-18T07:05:24.498885Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def trans_conv(X, K):\n",
    "    h, w = K.shape # 1. 获取卷积核的高度和宽度\n",
    "    # 2. 初始化输出矩阵\n",
    "    # 输出尺寸 = 输入尺寸 + 卷积核尺寸 - 1\n",
    "    Y = torch.zeros((X.shape[0] + h - 1, X.shape[1] + w - 1))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            # 4. 将输入元素与整个卷积核相乘，加到输出的对应区域\n",
    "            Y[i: i + h, j: j + w] += X[i, j] * K\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3baa22e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "验证上述实现输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4077e",
   "metadata": {},
   "source": [
    "![](./img/转置卷积1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c6e2fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:24.503202Z",
     "iopub.status.busy": "2023-08-18T07:05:24.502646Z",
     "iopub.status.idle": "2023-08-18T07:05:24.531448Z",
     "shell.execute_reply": "2023-08-18T07:05:24.530730Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  1.],\n",
       "        [ 0.,  4.,  6.],\n",
       "        [ 4., 12.,  9.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "trans_conv(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9dd301",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "使用高级API获得相同的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9de6d80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:24.535386Z",
     "iopub.status.busy": "2023-08-18T07:05:24.534826Z",
     "iopub.status.idle": "2023-08-18T07:05:24.544484Z",
     "shell.execute_reply": "2023-08-18T07:05:24.543747Z"
    },
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  0.,  1.],\n",
       "          [ 0.,  4.,  6.],\n",
       "          [ 4., 12.,  9.]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2) # (batch, channel, height, width)\n",
    "# 第1个参数 1：输入通道数；第2个参数 1：输出通道数；\n",
    "# kernel_size=2：卷积核大小为 2×2；bias=False：不使用偏置项（与手动实现一致）\n",
    "tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, bias=False)\n",
    "# 将自定义卷积核 K 赋值给转置卷积层的权重参数。，这里K是之前定义的2×2卷积核矩阵。\n",
    "tconv.weight.data = K\n",
    "# 输出尺寸 = 输入尺寸 + 卷积核尺寸 - 1 = 2 + 2 - 1 = 3\n",
    "tconv(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8811b58",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "填充、步幅和多通道"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c452e351",
   "metadata": {},
   "source": [
    "具体运算过程<br>\n",
    "先计算无padding的完整输出（3×3）：<br>\n",
    "[a b c]<br>\n",
    "[d e f]<br>\n",
    "[g h i]<br>\n",
    "这个中间结果与你之前手动实现的 trans_conv(X, K) 完全相同。<br>\n",
    "再裁剪边缘：padding=1 表示从每边各裁剪1个像素，只保留中心区域：<br>\n",
    "[e]  ← 只保留这个中心元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd114de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:24.548040Z",
     "iopub.status.busy": "2023-08-18T07:05:24.547398Z",
     "iopub.status.idle": "2023-08-18T07:05:24.553659Z",
     "shell.execute_reply": "2023-08-18T07:05:24.552864Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4.]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在转置卷积中，padding 的作用是：裁剪输出边缘，而不是填充输入。\n",
    "# 计算公式：输出尺寸 = 输入尺寸 + 卷积核尺寸 - 1 - 2 × padding\n",
    "tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, padding=1, bias=False)\n",
    "tconv.weight.data = K\n",
    "tconv(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb5bdbf",
   "metadata": {},
   "source": [
    "| 输入元素       | 发射的块                  | 在输出中的位置         | 贡献值             |\n",
    "| ---------- | --------------------- | --------------- | --------------- |\n",
    "| `X[0,0]=0` | `0*K`                 | 左上角 (0,0)-(1,1) | 全0              |\n",
    "| `X[0,1]=1` | `1*K = [[0,1],[2,3]]` | 右上角 (0,2)-(1,3) | `[[0,1],[2,3]]` |\n",
    "| `X[1,0]=2` | `2*K = [[0,2],[4,6]]` | 左下角 (2,0)-(3,1) | `[[0,2],[4,6]]` |\n",
    "| `X[1,1]=3` | `3*K = [[0,3],[6,9]]` | 右下角 (2,2)-(3,3) | `[[0,3],[6,9]]` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc75c4c",
   "metadata": {},
   "source": [
    "![](./img/转置卷积2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48064406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:24.557362Z",
     "iopub.status.busy": "2023-08-18T07:05:24.556727Z",
     "iopub.status.idle": "2023-08-18T07:05:24.563081Z",
     "shell.execute_reply": "2023-08-18T07:05:24.562365Z"
    },
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 1.],\n",
       "          [0., 0., 2., 3.],\n",
       "          [0., 2., 0., 3.],\n",
       "          [4., 6., 6., 9.]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当 stride=2 时，转置卷积会上采样（放大）输入特征图，这是转置卷积最常见的用途。\n",
    "# 输出尺寸公式:输出尺寸 = (输入尺寸 - 1) × stride + 卷积核尺寸 - 2 × padding\n",
    "tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, stride=2, bias=False)\n",
    "tconv.weight.data = K\n",
    "tconv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e7033d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:24.566613Z",
     "iopub.status.busy": "2023-08-18T07:05:24.565990Z",
     "iopub.status.idle": "2023-08-18T07:05:24.577437Z",
     "shell.execute_reply": "2023-08-18T07:05:24.576434Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 10, 16, 16)) # (batch, channels, height, width)\n",
    "# 输出尺寸公式：output = floor((input + 2*padding - kernel) / stride + 1)\n",
    "conv = nn.Conv2d(10, 20, kernel_size=5, padding=2, stride=3)\n",
    "# 输出尺寸公式：output = (input - 1) * stride - 2*padding + kernel\n",
    "tconv = nn.ConvTranspose2d(20, 10, kernel_size=5, padding=2, stride=3)\n",
    "tconv(conv(X)).shape == X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aa0878",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "与矩阵变换的联系"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2afd9b",
   "metadata": {},
   "source": [
    "Y[i,j] = sum( X[i:i+h, j:j+w] * K )其中 h=2, w=2 是卷积核的大小。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c319e37",
   "metadata": {},
   "source": [
    "✅ corr2d = 深度学习中的\"卷积\"（实际数学卷积需要翻转核，但深度学习中通常不翻转）<br>\n",
    "✅ 无填充、步长为1时：输出尺寸 = 输入尺寸 - 卷积核尺寸 + 1<br>\n",
    "✅ 运算本质是：卷积核K在X上滑动，逐元素相乘再求和（点积）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b1328",
   "metadata": {},
   "source": [
    "1. 计算 Y[0,0]<br>\n",
    "X[0:2, 0:2] = [[0., 1.],[3., 4.]]\n",
    "Y[0,0] = 0*1 + 1*2 + 3*3 + 4*4 = 0 + 2 + 9 + 16 = 27<br>\n",
    "2. 计算 Y[0,1]<br>\n",
    "X[0:2, 1:3] = [[1., 2.],[4., 5.]]\n",
    "Y[0,1] = 1*1 + 2*2 + 4*3 + 5*4 = 1 + 4 + 12 + 20 = 37<br>\n",
    "3. 计算 Y[1,0]<br>\n",
    "X[1:3, 0:2] = [[3., 4.],[6., 7.]]\n",
    "Y[1,0] = 3*1 + 4*2 + 6*3 + 7*4 = 3 + 8 + 18 + 28 = 57<br>\n",
    "4. 计算 Y[1,1]<BR>\n",
    "X[1:3, 1:3] = [[4., 5.],[7., 8.]]\n",
    "Y[1,1] = 4*1 + 5*2 + 7*3 + 8*4 = 4 + 10 + 21 + 32 = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "260d5c6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:24.581485Z",
     "iopub.status.busy": "2023-08-18T07:05:24.580866Z",
     "iopub.status.idle": "2023-08-18T07:05:24.589179Z",
     "shell.execute_reply": "2023-08-18T07:05:24.588233Z"
    },
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27., 37.],\n",
       "        [57., 67.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X = [[0., 1., 2.],\n",
    "    [3., 4., 5.],\n",
    "    [6., 7., 8.]]\n",
    "'''\n",
    "X = torch.arange(9.0).reshape(3, 3)\n",
    "K = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "Y = d2l.corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f6ce2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:24.592769Z",
     "iopub.status.busy": "2023-08-18T07:05:24.592164Z",
     "iopub.status.idle": "2023-08-18T07:05:24.602392Z",
     "shell.execute_reply": "2023-08-18T07:05:24.601439Z"
    },
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 3., 4., 0., 0., 0., 0.],\n",
       "        [0., 1., 2., 0., 3., 4., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 2., 0., 3., 4., 0.],\n",
       "        [0., 0., 0., 0., 1., 2., 0., 3., 4.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kernel2matrix(K):\n",
    "    # 1. 创建长度为5的零向量k，和4×9的零矩阵W\n",
    "    k, W = torch.zeros(5), torch.zeros((4, 9))\n",
    "    '''\n",
    "    2. 将2×2核K的元素填充到k的特殊位置\n",
    "    k[0]=a, k[1]=b, k[3]=c, k[4]=d\n",
    "    此时 k = [a, b, 0, c, d]  （中间故意留0）\n",
    "    '''\n",
    "    k[:2], k[3:5] = K[0, :], K[1, :]\n",
    "    '''\n",
    "    3. 将k以滑动窗口方式填充到W的每一行\n",
    "    第0行: [a, b, 0, c, d, 0, 0, 0, 0]\n",
    "    第1行: [0, a, b, 0, c, d, 0, 0, 0]\n",
    "    第2行: [0, 0, 0, a, b, 0, c, d, 0]\n",
    "    第3行: [0, 0, 0, 0, a, b, 0, c, d]\n",
    "    '''\n",
    "    W[0, :5], W[1, 1:6], W[2, 3:8], W[3, 4:] = k, k, k, k\n",
    "    return W\n",
    "\n",
    "W = kernel2matrix(K)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fb803d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:24.606249Z",
     "iopub.status.busy": "2023-08-18T07:05:24.605496Z",
     "iopub.status.idle": "2023-08-18T07:05:24.612872Z",
     "shell.execute_reply": "2023-08-18T07:05:24.611900Z"
    },
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. X.reshape(-1)——展平输入:将3×3的输入矩阵X展平成9×1的列向量\n",
    "2. torch.matmul(W, X.reshape(-1))——矩阵乘法\n",
    "W是4×9矩阵，X是9×1向量，结果是一个4×1向量：W(4×9)×X(9×1)=Temp(4×1)\n",
    "3. .reshape(2, 2) —— 重塑为卷积输出形状:将4×1向量重新排列成2×2矩阵（与原卷积输出Y同形状）\n",
    "4. Y == ... —— 逐元素相等性检查:返回一个2×2的布尔张量，验证两种方式结果是否一致\n",
    "'''\n",
    "Y == torch.matmul(W, X.reshape(-1)).reshape(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1a55ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:24.616575Z",
     "iopub.status.busy": "2023-08-18T07:05:24.615826Z",
     "iopub.status.idle": "2023-08-18T07:05:24.623063Z",
     "shell.execute_reply": "2023-08-18T07:05:24.622144Z"
    },
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. Z = trans_conv(Y, K)\n",
    "Y:普通卷积的输出（2×2）;K:2×2卷积核;trans_conv:手动实现的转置卷积函数;Z:结果（3×3），尺寸还原为原始输入X的大小\n",
    "2. W.T\n",
    "之前kernel2matrix(K)构造的矩阵W的转置;如果W是4×9（将3×3 → 2×2）;那么W.T就是9×4（将2×2→3×3）\n",
    "3. torch.matmul(W.T, Y.reshape(-1))\n",
    "将2×2的Y展平成4×1向量;用9×4的W.T乘4×1的Y→9×1的临时向量;等价于执行了转置卷积的线性变换\n",
    "4. .reshape(3, 3)\n",
    "将9×1向量重塑为3×3矩阵，与Z同形状\n",
    "'''\n",
    "Z = trans_conv(Y, K)\n",
    "Z == torch.matmul(W.T, Y.reshape(-1)).reshape(3, 3)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "required_libs": [],
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
