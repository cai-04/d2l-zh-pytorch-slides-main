{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0160c8de",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 词的相似性和类比任务\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23dc33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:41.256400Z",
     "iopub.status.busy": "2023-08-18T07:06:41.255749Z",
     "iopub.status.idle": "2023-08-18T07:06:43.288113Z",
     "shell.execute_reply": "2023-08-18T07:06:43.287240Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6db3d6",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "## 加载预训练词向量\n",
    "\n",
    "以下列出维度为50、100和300的预训练GloVe嵌入，可从[GloVe网站](https://nlp.stanford.edu/projects/glove/)下载。预训练的fastText嵌入有多种语言。这里我们使用可以从[fastText网站](https://fasttext.cc/)下载300维度的英文版本（“wiki.en”）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f705ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:43.292543Z",
     "iopub.status.busy": "2023-08-18T07:06:43.291837Z",
     "iopub.status.idle": "2023-08-18T07:06:43.297097Z",
     "shell.execute_reply": "2023-08-18T07:06:43.296299Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['glove.6b.50d'] = (d2l.DATA_URL + 'glove.6B.50d.zip',\n",
    "                                '0b8703943ccdb6eb788e6f091b8946e82231bc4d')\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['glove.6b.100d'] = (d2l.DATA_URL + 'glove.6B.100d.zip',\n",
    "                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['glove.42b.300d'] = (d2l.DATA_URL + 'glove.42B.300d.zip',\n",
    "                                  'b5116e234e9eb9076672cfeabf5469f3eec904fa')\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['wiki.en'] = (d2l.DATA_URL + 'wiki.en.zip',\n",
    "                           'c1816da3821ae9f43899be655002f6c723e91b88')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368bbae",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "**为什么需要双向映射？**\n",
    "| 属性                 | 类型 | 用途                |\n",
    "| ------------------ | -- | ----------------- |\n",
    "| **`idx_to_token`** | 列表 | **索引转单词**（用于展示结果） |\n",
    "| **`token_to_idx`** | 字典 | **单词转索引**（用于查询向量） |\n",
    "\n",
    "**完整数据流动**\n",
    "```Python\n",
    "# 实例化\n",
    "glove = TokenEmbedding('glove.6B.50d')\n",
    "\n",
    "# 内部结构\n",
    "glove.idx_to_token  # → ['<unk>', 'the', 'of', 'and', ...]\n",
    "glove.idx_to_vec    # → tensor([[0.0, 0.0, ...], [0.046, 0.213, ...], ...])\n",
    "glove.unknown_idx   # → 0\n",
    "glove.token_to_idx  # → {'<unk>': 0, 'the': 1, 'of': 2, ...}\n",
    "```\n",
    "\n",
    "| 代码行                         | 功能      | 关键技术        |\n",
    "| --------------------------- | ------- | ----------- |\n",
    "| `self._load_embedding(...)` | 加载预训练向量 | 自动下载 + 文本解析 |\n",
    "| `self.unknown_idx = 0`      | OOV词处理  | 默认索引机制      |\n",
    "| `字典推导式`                     | 构建反向映射  | O(1)查询效率    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ffc516",
   "metadata": {},
   "source": [
    "**每个部分的含义**\n",
    "\n",
    "`len(idx_to_vec[0])  ：获取词向量的维度（如 50, 100, 300）`\n",
    "```Python\n",
    "idx_to_vec[0]  # → [0.04656, 0.21318, ...]\n",
    "len(idx_to_vec[0])  # → 50（假设是50维）\n",
    "[0] * len(idx_to_vec[0])  ：创建一个全零列表\n",
    "```\n",
    "```Python\n",
    "[0] * 50  # → [0, 0, 0, ..., 0]（50个0）\n",
    "[[0] * len(idx_to_vec[0])]  ：包装成二维列表（单个向量）\n",
    "```\n",
    "```Python\n",
    "[[0, 0, 0, ..., 0]]  # → 形状: (1, 50)\n",
    "+ idx_to_vec  ：列表拼接，将全零向量放在最前面\n",
    "```\n",
    "```Python\n",
    "[[0,0,...,0]] + [[0.04656,...], [-0.071549,...], ...]\n",
    "# → [[0,0,...,0], [0.04656,...], [-0.071549,...], ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9bedaa",
   "metadata": {},
   "source": [
    "1. 将单词转换为索引\n",
    "```Python\n",
    "indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
    "           for token in tokens]\n",
    "```\n",
    "**列表推导式分解：**\n",
    "\n",
    "外层：遍历 `tokens` 列表中的每个 `token`\n",
    "内层：`self.token_to_idx.get(token, self.unknown_idx)`\n",
    "\n",
    "**dict.get(key, default)的作用：**\n",
    "```python\n",
    "# 如果 token 在字典中\n",
    "self.token_to_token['chip']  # → 返回对应的索引，如 305\n",
    "\n",
    "# 如果 token 不在字典中\n",
    "self.token_to_token['unknownword']  # → 返回 self.unknown_idx (0)\n",
    "避免 KeyError：即使查询未知词，也不会报错，而是返回 <unk> 的索引。\n",
    "```\n",
    "2. 从张量中提取向量\n",
    "```Python\n",
    "vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "```\n",
    "**执行过程：**\n",
    "```Python\n",
    "# 假设 indices = [305, 102, 0] (chip, cpu, <unk>)\n",
    "idx_tensor = torch.tensor(indices)  # → tensor([305, 102, 0])\n",
    "\n",
    "# PyTorch 高级索引：一次性提取多行\n",
    "vecs = self.idx_to_vec[idx_tensor]\n",
    "# → 返回形状为 (3, embed_dim) 的张量\n",
    "```\n",
    "**索引机制：**\n",
    "\n",
    "`self.idx_to_vec` 形状：(词表大小, 向量维度)\n",
    "\n",
    "`torch.tensor(indices)` 形状：(查询词数量,)\n",
    "\n",
    "结果：返回 [305, 102, 0] 行对应的向量，形状 (查询词数量, 向量维度)\n",
    "\n",
    "3. 返回结果\n",
    "```Python\n",
    "return vecs\n",
    "```\n",
    "返回值：torch.Tensor，可直接用于神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd54118c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:43.300883Z",
     "iopub.status.busy": "2023-08-18T07:06:43.300205Z",
     "iopub.status.idle": "2023-08-18T07:06:43.309328Z",
     "shell.execute_reply": "2023-08-18T07:06:43.308481Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class TokenEmbedding:\n",
    "    \"\"\"GloVe嵌入\"\"\"\n",
    "    '''\n",
    "    embedding_name：预训练嵌入名称（如'glove.6B.100d'）\n",
    "    idx_to_token：索引→单词的列表（如['<unk>','the','of',...]）\n",
    "    idx_to_vec：索引→向量的张量（形状：(词表大小,嵌入维度)）\n",
    "    unknown_idx=0：未知词默认映射到索引0（<unk>）\n",
    "    token_to_idx：单词→索引的字典，用于快速查询\n",
    "    '''\n",
    "    def __init__(self, embedding_name):\n",
    "        '''\n",
    "        1. 加载预训练嵌入\n",
    "        调用：_load_embedding()方法自动下载并解析词向量文件\n",
    "        返回：两个对象\n",
    "            idx_to_token：列表，索引→单词（如 ['<unk>','the','of',...]）\n",
    "            idx_to_vec：张量，索引→向量（形状 [词表大小,嵌入维度]）\n",
    "        '''\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding(\n",
    "            embedding_name)\n",
    "        '''\n",
    "        2. 设置未知词索引\n",
    "        作用：为未登录词（OOV）指定默认索引\n",
    "        约定：索引0通常为特殊词<unk>（Unknown）\n",
    "        意义：查询不存在单词时返回该索引\n",
    "        '''\n",
    "        self.unknown_idx = 0\n",
    "        '''\n",
    "        3. 构建反向映射字典\n",
    "        字典推导式：将idx_to_token列表反转\n",
    "        结果：token_to_idx是单词→索引的字典（如{'the':1,'of':2}）\n",
    "        目的：实现O(1)时间复杂度的单词快速查找\n",
    "        '''\n",
    "        self.token_to_idx = {token: idx for idx, token in\n",
    "                             enumerate(self.idx_to_token)}\n",
    "    # 加载嵌入文件\n",
    "    def _load_embedding(self, embedding_name):\n",
    "        '''\n",
    "        1. 初始化容器\n",
    "        idx_to_token=['<unk>']：预先放入未知词符号，确保索引0是<unk>\n",
    "        idx_to_vec=[]：向量列表暂时为空（后续动态填充）\n",
    "        '''\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "        # 2. 下载并解压文件\n",
    "        data_dir = d2l.download_extract(embedding_name)\n",
    "        # GloVe网站：https://nlp.stanford.edu/projects/glove/\n",
    "        # fastText网站：https://fasttext.cc/\n",
    "        # 3. 打开向量文件\n",
    "        # 文件路径：{data_dir}/vec.txt；文件格式：纯文本，每行是一个词+向量\n",
    "        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n",
    "            '''\n",
    "            4. 逐行解析\n",
    "            line.rstrip().split(' ')：移除换行符并空格分割\n",
    "            elems[0]：第一个元素是单词（如'the'）\n",
    "            elems[1:]：剩余元素是向量维度（字符串列表）\n",
    "            [float(elem)...]：转换为浮点数列表\n",
    "            '''\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                '''\n",
    "                5. 跳过标题行\n",
    "                目的：跳过文件开头的元信息行（如fastText的首行）\n",
    "                判断：有效向量行至少有1个维度，len(elems)>1确保不是空行或标题\n",
    "                追加：将词和向量分别加入对应列表\n",
    "                '''\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        '''\n",
    "        6. 插入未知词向量\n",
    "        操作：在索引0处插入全零向量作为<unk>的嵌入\n",
    "        维度：len(idx_to_vec[0])获取第一个向量的长度（如50、100、300）\n",
    "        结果：idx_to_vec[0]是全零向量，对应idx_to_token[0]='<unk>'\n",
    "        '''\n",
    "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
    "        '''\n",
    "        7. 转换为PyTorch张量\n",
    "        torch.tensor(idx_to_vec)：将嵌套列表转为PyTorch张量\n",
    "        形状：(词表大小,嵌入维度)\n",
    "        优点：可直接用于神经网络，支持GPU加速\n",
    "        '''\n",
    "        return idx_to_token, torch.tensor(idx_to_vec)\n",
    "    # 索引访问\n",
    "    def __getitem__(self, tokens):\n",
    "        '''\n",
    "        self.token_to_idx ：单词→索引的字典（如 {'chip':305,'cpu':102}）\n",
    "        .get(key,default)：字典的安全查询方法\n",
    "            如果key存在，返回对应值\n",
    "            如果key不存在，返回default（避免KeyError）\n",
    "        '''\n",
    "        indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
    "                   for token in tokens]\n",
    "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "        return vecs\n",
    "    # 获取词表大小\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6375fd2e",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "下面我们加载50维GloVe嵌入（在维基百科的子集上预训练）。创建`TokenEmbedding`实例时，如果尚未下载指定的嵌入文件，则必须下载该文件。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac49581b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:43.312986Z",
     "iopub.status.busy": "2023-08-18T07:06:43.312409Z",
     "iopub.status.idle": "2023-08-18T07:06:54.396038Z",
     "shell.execute_reply": "2023-08-18T07:06:54.395176Z"
    },
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ..\\data\\glove.6B.50d.zip from http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.50d.zip...\n"
     ]
    }
   ],
   "source": [
    "glove_6b50d = TokenEmbedding('glove.6b.50d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f30d4e",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "输出词表大小。词表包含400000个词（词元）和一个特殊的未知词元。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d91a982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:54.400162Z",
     "iopub.status.busy": "2023-08-18T07:06:54.399579Z",
     "iopub.status.idle": "2023-08-18T07:06:54.405466Z",
     "shell.execute_reply": "2023-08-18T07:06:54.404676Z"
    },
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f2106",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "我们可以得到词表中一个单词的索引，反之亦然。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e10f262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:54.408746Z",
     "iopub.status.busy": "2023-08-18T07:06:54.408294Z",
     "iopub.status.idle": "2023-08-18T07:06:54.413468Z",
     "shell.execute_reply": "2023-08-18T07:06:54.412687Z"
    },
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beautiful'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "token_to_idx：单词→索引的字典\n",
    "作用：查询单词'beautiful'在词汇表中的索引\n",
    "返回值：整数（如3367）\n",
    "idx_to_token：索引→单词的列表\n",
    "作用：查询索引3367对应的单词\n",
    "返回值：字符串（如'beautiful'）\n",
    "'''\n",
    "glove_6b50d.token_to_idx['beautiful'], \n",
    "glove_6b50d.idx_to_token[3367]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6c303",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "## 应用预训练词向量\n",
    "\n",
    "使用加载的GloVe向量，我们将通过下面的词相似性和类比任务中来展示词向量的语义。\n",
    "\n",
    "### 词相似度\n",
    "\n",
    "与`subsec_apply-word-embed`类似，为了根据词向量之间的余弦相似性为输入词查找语义相似的词，我们实现了以下`knn`（$k$近邻）函数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2da78732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:54.416901Z",
     "iopub.status.busy": "2023-08-18T07:06:54.416268Z",
     "iopub.status.idle": "2023-08-18T07:06:54.421648Z",
     "shell.execute_reply": "2023-08-18T07:06:54.420466Z"
    },
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "W：词向量矩阵，形状(词表大小,向量维度)\n",
    "x：查询向量，形状(向量维度,)或(1,向量维度)\n",
    "k：返回最相似的k个词\n",
    "topk：最相似词的索引列表\n",
    "[cos[int(i)] for i in topk]：对应的余弦相似度分数列表\n",
    "'''\n",
    "def knn(W, x, k):\n",
    "\n",
    "    '''\n",
    "\n",
    "    1. 计算余弦相似度\n",
    "    增加1e-9以获得数值稳定性\n",
    "    分子：点积\n",
    "        x.reshape(-1,)：将查询向量展平为一维（如(300,)→(300,)）\n",
    "        torch.mv(W,x)：矩阵-向量乘法，计算每个词向量与查询向量的点积\n",
    "        结果：形状 (词表大小,)，每个元素是Wi⋅x \n",
    "    分母：模长乘积\n",
    "        torch.sum(W*W, axis=1)：每个词向量的模长平方（逐元素平方后求和）\n",
    "        +1e-9：数值稳定性，防止除零错误\n",
    "        torch.sqrt(...)：词向量的模长||Wi||\n",
    "        (x*x).sum()：查询向量的模长平方||x||^2\n",
    "        torch.sqrt(...)：查询向量的模长||x|| \n",
    "        整体：||Wi||⋅||x||\n",
    "        结果：cos 是形状为(词表大小,)的张量，元素范围[-1,1]\n",
    "    '''\n",
    "    cos = torch.mv(W, x.reshape(-1,)) / (\n",
    "        torch.sqrt(torch.sum(W * W, axis=1) + 1e-9) *\n",
    "        torch.sqrt((x * x).sum()))\n",
    "    '''\n",
    "    2. 返回最相似的k个词\n",
    "    torch.topk(cos,k=k) ：返回cos中最大的k个值及其索引\n",
    "    _：忽略值（相似度分数，后面会重新提取）\n",
    "    topk：索引张量，形状(k,)，表示最相似的k个词的位置\n",
    "    '''\n",
    "    _, topk = torch.topk(cos, k=k)\n",
    "    '''\n",
    "    3. 提取相似度分数\n",
    "    topk：索引列表（如tensor([3367,102,89])）\n",
    "    列表推导式：遍历每个索引i，从cos中提取对应分数\n",
    "    int(i)：将张量元素转为Python整数（用于索引）\n",
    "    结果：返回(索引列表,分数列表)元组\n",
    "    '''\n",
    "    return topk, [cos[int(i)] for i in topk]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a758d",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "然后，我们使用`TokenEmbedding`的实例`embed`中预训练好的词向量来搜索相似的词。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b1da561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:54.425376Z",
     "iopub.status.busy": "2023-08-18T07:06:54.424618Z",
     "iopub.status.idle": "2023-08-18T07:06:54.430025Z",
     "shell.execute_reply": "2023-08-18T07:06:54.428981Z"
    },
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "query_token：查询词（如'beautiful'）\n",
    "k：返回最相似的词数量\n",
    "embed：TokenEmbedding实例（包含词向量）\n",
    "'''\n",
    "def get_similar_tokens(query_token, k, embed):\n",
    "    '''\n",
    "    1. 查找最相似的 k+1 个词\n",
    "    为什么k+1？\n",
    "    因为查询词本身的相似度最高（cosine=1.0），必然排在第一位。我们需要排除自己，所以查找k+1个，然后跳过第一个\n",
    "    参数详解：\n",
    "    embed.idx_to_vec：所有词的向量矩阵，形状(词表大小,向量维度)\n",
    "    embed[[query_token]]：查询词的向量，形状(1,向量维度)\n",
    "    k+1：返回数量（包含查询词本身）\n",
    "    返回结果：\n",
    "        topk：索引张量，如[query_idx,sim_idx1,sim_idx2,...]\n",
    "        cos：相似度列表，如[1.0,0.89,0.85,...]\n",
    "    '''\n",
    "    topk, cos = knn(embed.idx_to_vec, embed[[query_token]], k + 1)\n",
    "    '''\n",
    "    2. 跳过查询词，遍历结果\n",
    "    topk[1:]：从第2个元素开始（排除查询词的索引）\n",
    "    cos[1:]：从第2个元素开始（排除查询词的相似度1.0）\n",
    "    zip(...,...)：将索引和相似度配对遍历\n",
    "    第1次循环：i=topk[1],c=cos[1]\n",
    "    第2次循环：i=topk[2],c=cos[2]\n",
    "    '''\n",
    "    for i, c in zip(topk[1:], cos[1:]):  # 排除输入词\n",
    "        '''\n",
    "        embed.idx_to_token[int(i)]：将索引转换为单词\n",
    "        float(c)：将张量转为浮点数\n",
    "        :.3f：格式化输出，保留3位小数\n",
    "        '''\n",
    "\n",
    "        print(f'{embed.idx_to_token[int(i)]}：cosine相似度={float(c):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba6f5c8",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "**执行流程**\n",
    "\n",
    "**第一步：获取查询词向量**\n",
    "```Python\n",
    "embed[['chip']]  # glove_6b50d[['chip']]\n",
    "```\n",
    "- 在 glove_6b50d 中查找 'chip' 的词向量\n",
    "- 结果：形状 (1, 50) 的张量\n",
    "\n",
    "**第二步：执行K近邻搜索（查找4个）**\n",
    "```Python\n",
    "knn(embed.idx_to_vec, embed[['chip']], k=4)  # 注意：k+1=4\n",
    "```\n",
    "- 计算 'chip' 与词表中所有词的余弦相似度\n",
    "- 返回：最相似的 4 个词的索引和相似度\n",
    "**为什么查找4个？**\n",
    "\n",
    "因为 'chip' 本身的相似度是 1.0，必然排在第一位。需要排除自己，所以查找 3+1=4 个。\n",
    "\n",
    "**第三步：处理结果并打印**\n",
    "```Python\n",
    "for i, c in zip(topk[1:], cos[1:]):  # 跳过第一个（查询词自己）\n",
    "    print(f'{embed.idx_to_token[int(i)]}：cosine相似度={float(c):.3f}')\n",
    "```\n",
    "**预期输出示例**\n",
    "\n",
    "基于语义相关性，可能的输出如下：\n",
    "```python\n",
    "processor：cosine相似度=0.756\n",
    "memory：cosine相似度=0.732\n",
    "cpu：cosine相似度=0.718\n",
    "```\n",
    "**为什么是这些词？**\n",
    "- 'chip' 在语义上与计算机硬件相关\n",
    "- 'processor'（处理器）、'memory'（内存）、'cpu'（中央处理器）都与芯片紧密相关\n",
    "\n",
    "**不同词向量的结果差异**\n",
    "\n",
    "**如果使用 glove_6b50d（50维）**\n",
    "- 结果可能偏向通用语义\n",
    "- 相似度分数相对较低（0.6-0.8）\n",
    "\n",
    "**如果使用 glove_6b100d（100维）**\n",
    "```Python\n",
    "get_similar_tokens('chip', 3, glove_6b100d)\n",
    "# 可能输出：\n",
    "# microprocessor：cosine相似度=0.812\n",
    "# semiconductor：cosine相似度=0.798\n",
    "# cpu：cosine相似度=0.785\n",
    "```\n",
    "- 更高维度的词向量语义更精确\n",
    "- 可能出现更专业的词（如 microprocessor, semiconductor）\n",
    "\n",
    "**无效查询的处理**\n",
    "\n",
    "**查询不在词表中的词**\n",
    "```Python\n",
    "get_similar_tokens('nonexistentword', 3, glove_6b50d)\n",
    "```\n",
    "**输出：**\n",
    "```python\n",
    "<unk>：cosine相似度=0.000\n",
    "<unk>：cosine相似度=0.000\n",
    "<unk>：cosine相似度=0.000\n",
    "```\n",
    "因为未知词被映射到 <unk>，其向量是全零向量，与所有词的相似度都是0。\n",
    "\n",
    "**查询特殊词**\n",
    "```Python\n",
    "get_similar_tokens('<unk>', 3, glove_6b50d)\n",
    "# 输出：<unk>相关的词（通常是低频词）\n",
    "```\n",
    "**调试技巧**\n",
    "\n",
    "**检查 'chip' 是否在词表中**\n",
    "```Python\n",
    "if 'chip' in glove_6b50d.token_to_idx:\n",
    "    print(f\"'chip' 的索引是: {glove_6b50d.token_to_idx['chip']}\")\n",
    "else:\n",
    "    print(\"'chip' 不在词表中，将被映射到 <unk>\")\n",
    " ```\n",
    "**查看 'chip' 的向量**\n",
    "```Python\n",
    "chip_vec = glove_6b50d[['chip']]\n",
    "print(chip_vec.shape)  # → torch.Size([1, 50])\n",
    "print(chip_vec[:5])    # 打印前5维\n",
    "```\n",
    "**手动验证结果**\n",
    "```Python\n",
    "# 获取最相似的词并检查是否真的相似\n",
    "topk, cos = knn(glove_6b50d.idx_to_vec, glove_6b50d[['chip']], 4)\n",
    "for i, c in zip(topk[1:], cos[1:]):\n",
    "    word = glove_6b50d.idx_to_token[int(i)]\n",
    "    print(f\"{word}: {float(c):.3f}\")\n",
    "\n",
    "# 检查第一个是否是 'chip' 自己\n",
    "first_word = glove_6b50d.idx_to_token[int(topk[0])]\n",
    "print(f\"第一个词是: {first_word} (应该是 'chip' 自己)\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "623bc4a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:54.433258Z",
     "iopub.status.busy": "2023-08-18T07:06:54.432943Z",
     "iopub.status.idle": "2023-08-18T07:06:54.481827Z",
     "shell.execute_reply": "2023-08-18T07:06:54.480628Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chips：cosine相似度=0.856\n",
      "intel：cosine相似度=0.749\n",
      "electronics：cosine相似度=0.749\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "'chip'：查询词（芯片）\n",
    "3：返回3个最相似的词\n",
    "glove_6b50d：GloVe 6B 50维词向量实例\n",
    "'''\n",
    "get_similar_tokens('chip', 3, glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18fa17a",
   "metadata": {
    "origin_pos": 22
   },
   "source": [
    "下面输出与“baby”和“beautiful”相似的词。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2fd5e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:54.486458Z",
     "iopub.status.busy": "2023-08-18T07:06:54.485962Z",
     "iopub.status.idle": "2023-08-18T07:06:54.508991Z",
     "shell.execute_reply": "2023-08-18T07:06:54.507938Z"
    },
    "origin_pos": 23,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babies：cosine相似度=0.839\n",
      "boy：cosine相似度=0.800\n",
      "girl：cosine相似度=0.792\n"
     ]
    }
   ],
   "source": [
    "get_similar_tokens('baby', 3, glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa9e2e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:54.513356Z",
     "iopub.status.busy": "2023-08-18T07:06:54.512976Z",
     "iopub.status.idle": "2023-08-18T07:06:54.534489Z",
     "shell.execute_reply": "2023-08-18T07:06:54.533425Z"
    },
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lovely：cosine相似度=0.921\n",
      "gorgeous：cosine相似度=0.893\n",
      "wonderful：cosine相似度=0.830\n"
     ]
    }
   ],
   "source": [
    "get_similar_tokens('beautiful', 3, glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc0553d",
   "metadata": {
    "origin_pos": 25
   },
   "source": [
    "### 词类比\n",
    "\n",
    "除了找到相似的词，我们还可以将词向量应用到词类比任务中。\n",
    "例如，“man” : “woman” :: “son” : “daughter”是一个词的类比。\n",
    "“man”是对“woman”的类比，“son”是对“daughter”的类比。\n",
    "具体来说，词类比任务可以定义为：\n",
    "对于单词类比$a : b :: c : d$，给出前三个词$a$、$b$和$c$，找到$d$。\n",
    "用$\\text{vec}(w)$表示词$w$的向量，\n",
    "为了完成这个类比，我们将找到一个词，\n",
    "其向量与$\\text{vec}(c)+\\text{vec}(b)-\\text{vec}(a)$的结果最相似。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42cf961",
   "metadata": {},
   "source": [
    "idx_to_vec 是 TokenEmbedding 类中的核心属性，是一个 PyTorch 张量，存储了词汇表中所有单词的词向量。\n",
    "\n",
    "**基本定义**\n",
    "```Python\n",
    "self.idx_to_vec  # 形状: (词表大小, 嵌入维度)\n",
    "```\n",
    "它是一个二维张量，每行对应一个单词的向量表示。\n",
    "\n",
    "**数据结构**\n",
    "\n",
    "**形状示例**\n",
    "```Python\n",
    "# 如果加载 GloVe 6B 50d\n",
    "idx_to_vec.shape  # → torch.Size([400001, 50])\n",
    "\n",
    "# 如果加载 GloVe 6B 100d\n",
    "idx_to_vec.shape  # → torch.Size([400001, 100])\n",
    "```\n",
    "**维度含义**\n",
    "- 第0维（400001）：词汇表大小（包含 <unk>）\n",
    "- 第1维（50或100）：词向量的维度\n",
    "\n",
    "**索引映射关系**\n",
    "\n",
    "idx_to_vec 与 idx_to_token 严格一一对应：\n",
    "\n",
    "| 索引   | `idx_to_token[i]` | `idx_to_vec[i]`            | 说明       |\n",
    "| ---- | ----------------- | -------------------------- | -------- |\n",
    "| 0    | `'<unk>'`         | `[0.0, 0.0, ..., 0.0]`     | 未知词，全零向量 |\n",
    "| 1    | `'the'`           | `[0.04656, 0.21318, ...]`  | 高频词      |\n",
    "| 2    | `','`             | `[0.12345, -0.06789, ...]` | 标点符号     |\n",
    "| 3    | `'.'`             | `[0.98765, 0.05432, ...]`  | 标点符号     |\n",
    "| ...  | ...               | ...                        | ...      |\n",
    "| 3367 | `'beautiful'`     | `[0.23456, -0.12345, ...]` | 具体单词     |\n",
    "\n",
    "**内容示例**\n",
    "```Python\n",
    "# 查看前5个词向量\n",
    "glove_6b50d.idx_to_vec[:5]\n",
    "# tensor([[ 0.0000,  0.0000,  ...,  0.0000],  # <unk>\n",
    "#         [ 0.0466,  0.2132,  ...,  0.0539],  # the\n",
    "#         [ 0.1234, -0.0679,  ...,  0.0456],  # ,\n",
    "#         [ 0.9877,  0.0543,  ...,  0.0234],  # .\n",
    "#         [ ... ]])                           # of\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5646ae",
   "metadata": {},
   "source": [
    "**为什么有效？（理论基础）**\n",
    "\n",
    "1. 分布式假设<br>\n",
    "\"一个词的含义由它周围的词决定\"。词向量训练时，语义相关的词在向量空间中 彼此接近。\n",
    "\n",
    "2. 线性子空间假设（Mikolov et al. 2013）<br>\n",
    "词向量空间中的语义关系是近似线性的：\n",
    "- \"性别\"关系：v(king) - v(man) ≈ v(queen) - v(woman)\n",
    "- \"首都\"关系：v(Paris) - v(France) ≈ v(Berlin) - v(Germany)\n",
    "\n",
    "3. 向量平移<br>\n",
    "v(king) - v(man) 是一个从\"man\"到\"king\"的平移向量\n",
    "\n",
    "将这个平移应用到 v(woman) 上，得到 v(queen)\n",
    "\n",
    "**几何可视化**\n",
    "```python\n",
    "      v(king) ≈ v(man) + (v(queen) - v(woman))\n",
    "\n",
    "          v(king)      v(queen)\n",
    "              *        *\n",
    "              |        |\n",
    "              |        |\n",
    "              *        *\n",
    "          v(man)      v(woman)\n",
    "\n",
    "          [王室+男性]   [王室+女性]\n",
    "```\n",
    "向量差 v(king) - v(man) ≈ 向量差 v(queen) - v(woman)\n",
    "\n",
    "**其他类比示例**\n",
    "\n",
    "**首都关系**\n",
    "```Python\n",
    "# Paris : France :: Berlin : Germany\n",
    "x = v(France) - v(Paris) + v(Berlin)  # 应接近 v(Germany)\n",
    "```\n",
    "**复数关系**\n",
    "```Python\n",
    "# mouse : mice :: child : children\n",
    "x = v(mice) - v(mouse) + v(child)  # 应接近 v(children)\n",
    "```\n",
    "**反义词关系**\n",
    "```python\n",
    "# big : small :: hot : cold\n",
    "x = v(small) - v(big) + v(hot)  # 应接近 v(cold)\n",
    "```\n",
    "**线性代数的本质**\n",
    "\n",
    "这个公式的本质是在向量空间中进行线性组合：\n",
    "- 向量减法 ：提取 语义差异（如\"王室\"属性）\n",
    "- 向量加法：组合语义（\"王室\" + \"女性\"）\n",
    "**目标：**找到满足 v(d) ≈ x 的词 d，即最近邻搜索。\n",
    "\n",
    "**局限性**\n",
    "\n",
    "虽然这个公式在很多情况下有效，但不是绝对可靠：\n",
    "- 多义性：bank 有\"银行\"和\"河岸\"两个意思，向量是混合表示\n",
    "- 文化偏差：词向量可能继承训练数据中的偏见（如性别、种族）\n",
    "- 非线性关系：某些语义关系无法被线性捕捉\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5340469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:54.539108Z",
     "iopub.status.busy": "2023-08-18T07:06:54.538593Z",
     "iopub.status.idle": "2023-08-18T07:06:54.544150Z",
     "shell.execute_reply": "2023-08-18T07:06:54.543191Z"
    },
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def get_analogy(token_a, token_b, token_c, embed):\n",
    "    '''\n",
    "    第一步：获取三个词向量\n",
    "    输入：三个词（如'man','king','woman'）\n",
    "    输出：形状为(3,向量维度)的张量\n",
    "    索引：\n",
    "        vecs[0]→v(token_a)（如v(man)）\n",
    "        vecs[1]→v(token_b)（如v(king)）\n",
    "        vecs[2]→v(token_c)（如v(woman）\n",
    "    '''\n",
    "    vecs = embed[[token_a, token_b, token_c]]\n",
    "    '''\n",
    "    第二步：执行向量运算\n",
    "    数学表达：x=v(king)-v(man)+v(woman)\n",
    "    语义解释：\n",
    "        v(king)-v(man)：去除\"男性\"属性，保留\"王室\"属性\n",
    "        +v(woman)：添加\"女性\"属性\n",
    "        结果：应该接近v(queen)\n",
    "    '''\n",
    "    x = vecs[1] - vecs[0] + vecs[2]\n",
    "    '''\n",
    "    第三步：寻找最相似的词\n",
    "    在词表中搜索与向量x最相似的1个词\n",
    "    topk：最相似词的索引（如queen的索引）\n",
    "    cos：相似度分数（应接近1.0）\n",
    "    '''\n",
    "    topk, cos = knn(embed.idx_to_vec, x, 1)\n",
    "    '''\n",
    "    第四步：返回结果词\n",
    "    将张量索引转为Python整数\n",
    "    通过idx_to_token将索引转为单词\n",
    "    返回：答案词（如'queen'）\n",
    "    '''\n",
    "    return embed.idx_to_token[int(topk[0])]  # 删除未知词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f2721",
   "metadata": {
    "origin_pos": 27
   },
   "source": [
    "让我们使用加载的词向量来验证“male-female”类比。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18831b9",
   "metadata": {},
   "source": [
    "**执行过程详解**\n",
    "\n",
    "**第一步：获取三个词向量**\n",
    "```Python\n",
    "vecs = glove_6b50d[['man', 'woman', 'son']]\n",
    "# vecs[0] = v('man')\n",
    "# vecs[1] = v('woman')\n",
    "# vecs[2] = v('son')\n",
    "```\n",
    "\n",
    "**第二步：执行向量运算**\n",
    "```Python\n",
    "x = vecs[1] - vecs[0] + vecs[2]\n",
    "# x = v('woman') - v('man') + v('son')\n",
    "```\n",
    "\n",
    "**语义解释：**\n",
    "- v('woman') - v('man') ：提取\"女性\"相对于\"男性\"的 语义差向量\n",
    "- **+ v('son')**：将该差向量应用到\"儿子\"上\n",
    "- 结果 x：应接近  **v('daughter')**\n",
    "\n",
    "**第三步：寻找最相似词**\n",
    "```Python\n",
    "topk, cos = knn(glove_6b50d.idx_to_vec, x, 1)\n",
    "```\n",
    "- 在词表中搜索与向量 x 最接近的词\n",
    "- topk[0]：答案词的索引\n",
    "- cos[0]  ：相似度分数（应接近1.0）\n",
    "\n",
    "**第四步：返回结果**\n",
    "```Python\n",
    "return glove_6b50d.idx_to_token[int(topk[0])]\n",
    "```\n",
    "- 将索引转换为单词字符串\n",
    "\n",
    "**预期输出**\n",
    "```Python\n",
    "result = get_analogy('man', 'woman', 'son', glove_6b50d)\n",
    "print(result)  # → 'daughter'\n",
    "```\n",
    "**可能的结果**\n",
    "\n",
    "**理想情况（词向量质量高）**：'daughter'\n",
    "\n",
    "**次优情况（50维可能不够精确）**\n",
    "```python\n",
    "# 可能返回语义相关的词：\n",
    "'girl'        # 女性孩子\n",
    "'daughter.'   # 带标点的变体\n",
    "'child'       # 泛化过度\n",
    "```\n",
    "**失败情况（输入词不在词表中）**\n",
    "```python\n",
    "# 如果 'son' 不在词表中，会被映射为 <unk>\n",
    "# 结果可能是无意义的词\n",
    "```\n",
    "**验证与调试**\n",
    "\n",
    "**检查输入词是否存在**\n",
    "```Python\n",
    "for token in ['man', 'woman', 'son']:\n",
    "    if token not in glove_6b50d.token_to_idx:\n",
    "        print(f\"'{token}' 不在词表中！\")\n",
    "# 确保都返回 False\n",
    "```\n",
    "**手动执行向量运算**\n",
    "```Python\n",
    "# 获取向量\n",
    "v_man = glove_6b50d[['man']]\n",
    "v_woman = glove_6b50d[['woman']]\n",
    "v_son = glove_6b50d[['son']]\n",
    "\n",
    "# 执行运算\n",
    "x = v_woman - v_man + v_son\n",
    "\n",
    "# 查看最近邻\n",
    "topk, cos = knn(glove_6b50d.idx_to_vec, x, 5)\n",
    "for i, c in zip(topk, cos):\n",
    "    print(f\"{glove_6b50d.idx_to_token[int(i)]}: {float(c):.3f}\")\n",
    "```\n",
    "**期望输出前五名：**\n",
    "```python\n",
    "daughter: 0.892  # 第1名\n",
    "girl: 0.845\n",
    "child: 0.812\n",
    "son: 0.798       # 输入词本身可能也接近\n",
    "boy: 0.765\n",
    "```\n",
    "**局限性**\n",
    "\n",
    "1. 维度限制\n",
    "\n",
    "50维 GloVe 可能无法完美捕捉复杂关系，300维版本效果更好。\n",
    "\n",
    "2. 词表覆盖\n",
    "\n",
    "如果 'man', 'woman', 'son' 中有词不在词表中，结果会无效。\n",
    "\n",
    "3. 社会偏见\n",
    "\n",
    "词向量可能包含训练数据的偏见，如：\n",
    "\n",
    "```Python\n",
    "# 经典偏见示例\n",
    "get_analogy('man', 'doctor', 'woman', glove)\n",
    "# 可能返回 'nurse'（反映性别刻板印象）\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e91de1ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:54.548236Z",
     "iopub.status.busy": "2023-08-18T07:06:54.547963Z",
     "iopub.status.idle": "2023-08-18T07:06:54.569097Z",
     "shell.execute_reply": "2023-08-18T07:06:54.568018Z"
    },
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'daughter'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('man', 'woman', 'son', glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1ce80",
   "metadata": {
    "origin_pos": 29
   },
   "source": [
    "下面完成一个“首都-国家”的类比：\n",
    "“beijing” : “china” :: “tokyo” : “japan”。\n",
    "这说明了预训练词向量中的语义。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16eb56d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:54.573551Z",
     "iopub.status.busy": "2023-08-18T07:06:54.573270Z",
     "iopub.status.idle": "2023-08-18T07:06:54.595104Z",
     "shell.execute_reply": "2023-08-18T07:06:54.594092Z"
    },
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japan'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('beijing', 'china', 'tokyo', glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595634f2",
   "metadata": {
    "origin_pos": 31
   },
   "source": [
    "另外，对于“bad” : “worst” :: “big” : “biggest”等“形容词-形容词最高级”的比喻，预训练词向量可以捕捉到句法信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d6395b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:54.599698Z",
     "iopub.status.busy": "2023-08-18T07:06:54.599313Z",
     "iopub.status.idle": "2023-08-18T07:06:54.621533Z",
     "shell.execute_reply": "2023-08-18T07:06:54.620486Z"
    },
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'biggest'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('bad', 'worst', 'big', glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6555f30",
   "metadata": {
    "origin_pos": 33
   },
   "source": [
    "为了演示在预训练词向量中捕捉到的过去式概念，我们可以使用“现在式-过去式”的类比来测试句法：“do” : “did” :: “go” : “went”。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "986fa401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:54.626086Z",
     "iopub.status.busy": "2023-08-18T07:06:54.625554Z",
     "iopub.status.idle": "2023-08-18T07:06:54.647570Z",
     "shell.execute_reply": "2023-08-18T07:06:54.646604Z"
    },
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'went'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('do', 'did', 'go', glove_6b50d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
