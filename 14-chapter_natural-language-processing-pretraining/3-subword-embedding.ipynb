{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eef48dc",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 子词嵌入\n",
    "\n",
    "\n",
    "## fastText模型\n",
    "\n",
    "\n",
    "\n",
    "## 字节对编码（Byte Pair Encoding）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70df59d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:35.604170Z",
     "iopub.status.busy": "2023-08-18T06:56:35.603510Z",
     "iopub.status.idle": "2023-08-18T06:56:35.611979Z",
     "shell.execute_reply": "2023-08-18T06:56:35.611231Z"
    },
    "origin_pos": 1,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "symbols = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "           'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "           '_', '[UNK]']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94dab27",
   "metadata": {
    "origin_pos": 3
   },
   "source": [
    "因为我们不考虑跨越词边界的符号对，所以我们只需要一个字典`raw_token_freqs`将词映射到数据集中的频率（出现次数）。注意，特殊符号`'_'`被附加到每个词的尾部，以便我们可以容易地从输出符号序列（例如，“a_all er_man”）恢复单词序列（例如，“a_all er_man”）。由于我们仅从单个字符和特殊符号的词开始合并处理，所以在每个词（词典`token_freqs`的键）内的每对连续字符之间插入空格。换句话说，空格是词中符号之间的分隔符。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984db358",
   "metadata": {},
   "source": [
    "**步骤分解（以 'fast_' 为例）：**\n",
    "**list(token) ：将字符串拆分为 字符列表**\n",
    "```Python\n",
    "list('fast_')  # → ['f', 'a', 's', 't', '_']\n",
    "' '.join(...) ：用 空格连接字符\n",
    "```\n",
    "```Python\n",
    "' '.join(['f', 'a', 's', 't', '_'])  # → 'f a s t _'\n",
    "```\n",
    "**转换结果**\n",
    "```Python\n",
    "token_freqs = {\n",
    "    'f a s t _': 4,      # 由 'fast_' 转换而来\n",
    "    'f a s t e r _': 3,  # 由 'faster_' 转换而来\n",
    "    't a l l _': 5,      # 由 'tall_' 转换而来\n",
    "    't a l l e r _': 4   # 由 'taller_' 转换而来\n",
    "}\n",
    "```\n",
    "**为什么这样做？**<br>\n",
    "这种转换通常用于子词级别的模型（如Byte-Pair Encoding, BPE）或字符级语言模型：\n",
    "\n",
    "1. 用途1：字符级建模\n",
    "将每个单词视为字符序列，模型学习字符间的模式：<br>\n",
    "fast_ → f a s t _<br>\n",
    "模型可以捕捉 \"a s t\" 这个后缀模式<br>\n",
    "\n",
    "2. 用途2：子词单元（Subword Units）<br>\n",
    "在BPE或WordPiece分词中，将单词拆分为更小的单元：<br>\n",
    "f a s t → 可能合并为 fa st<br>\n",
    "处理未登录词（OOV）：即使没见过 \"fastest\"，也能用字符级信息推断<br>\n",
    "\n",
    "3. 用途3：形态学分析<br>\n",
    "帮助模型识别词根、前缀、后缀：<br>\n",
    "fast_ vs faster_：共享 \"fast\" 部分<br>\n",
    "er_ 后缀表明比较级"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a26ec96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:35.615843Z",
     "iopub.status.busy": "2023-08-18T06:56:35.615201Z",
     "iopub.status.idle": "2023-08-18T06:56:35.623942Z",
     "shell.execute_reply": "2023-08-18T06:56:35.623209Z"
    },
    "origin_pos": 4,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f a s t _': 4, 'f a s t e r _': 3, 't a l l _': 5, 't a l l e r _': 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_token_freqs = {'fast_': 4, 'faster_': 3, 'tall_': 5, 'taller_': 4}\n",
    "token_freqs = {}\n",
    "for token, freq in raw_token_freqs.items():\n",
    "    token_freqs[' '.join(list(token))] = raw_token_freqs[token]\n",
    "token_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2d216",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "我们定义以下`get_max_freq_pair`函数，其返回词内最频繁的连续符号对，其中词来自输入词典`token_freqs`的键。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708bffb4",
   "metadata": {},
   "source": [
    "| 词项       | 频率 | 字符对        | 累计频率        |\n",
    "| -------- | -- | ---------- | ----------- |\n",
    "| fast\\_   | 4  | ('f','a')  | +4 → 4      |\n",
    "|          |    | ('a','s')  | +4 → 4      |\n",
    "|          |    | ('s','t')  | +4 → 4      |\n",
    "|          |    | ('t','\\_') | +4 → 4      |\n",
    "| faster\\_ | 3  | ('f','a')  | +3 → **7**  |\n",
    "|          |    | ('a','s')  | +3 → **7**  |\n",
    "|          |    | ('s','t')  | +3 → **7**  |\n",
    "|          |    | ('t','e')  | +3 → 3      |\n",
    "|          |    | ('e','r')  | +3 → 3      |\n",
    "|          |    | ('r','\\_') | +3 → 3      |\n",
    "| tall\\_   | 5  | ('t','a')  | +5 → 9      |\n",
    "|          |    | ('a','l')  | +5 → 5      |\n",
    "|          |    | ('l','l')  | +5 → 5      |\n",
    "|          |    | ('l','\\_') | +5 → 5      |\n",
    "| taller\\_ | 4  | ('t','a')  | +4 → **13** |\n",
    "|          |    | ('a','l')  | +4 → **9**  |\n",
    "|          |    | ('l','l')  | +4 → **9**  |\n",
    "|          |    | ('l','e')  | +4 → 4      |\n",
    "|          |    | ('e','r')  | +4 → **7**  |\n",
    "|          |    | ('r','\\_') | +4 → **7**  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874de73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:35.627616Z",
     "iopub.status.busy": "2023-08-18T06:56:35.627025Z",
     "iopub.status.idle": "2023-08-18T06:56:35.631950Z",
     "shell.execute_reply": "2023-08-18T06:56:35.631221Z"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def get_max_freq_pair(token_freqs):\n",
    "    # 1. 创建字符对计数器：用途：统计每个字符对的出现频率\n",
    "    # defaultdict(int)：当访问不存在的键时，自动初始化为0\n",
    "    pairs = collections.defaultdict(int)\n",
    "    # 2. 遍历所有词项\n",
    "    # token.split()：将字符序列拆分为列表（如'f a s t _'→['f','a','s','t','_']）\n",
    "    for token, freq in token_freqs.items():\n",
    "        symbols = token.split()\n",
    "        '''\n",
    "        3. 统计相邻字符对\n",
    "        有效对数=字符数-1\n",
    "        滑动窗口：遍历所有相邻字符对\n",
    "        (symbols[i],symbols[i+1])：构成字符对元组（如('f','a')）\n",
    "        +=freq：将该词的出现次数累加到对应字符对\n",
    "        '''\n",
    "        for i in range(len(symbols) - 1):\n",
    "            # “pairs”的键是两个连续符号的元组\n",
    "            pairs[symbols[i], symbols[i + 1]] += freq\n",
    "    # 4. 返回最高频字符对\n",
    "    # pairs.get：获取字符对的频率值；max(...,key=...)：返回频率最高的字符对\n",
    "    return max(pairs, key=pairs.get)  # 具有最大值的“pairs”键"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a4399",
   "metadata": {
    "origin_pos": 7
   },
   "source": [
    "**输入**\n",
    "```Python\n",
    "max_freq_pair = ('t', 'a')\n",
    "token_freqs = {\n",
    "    't a l l _': 5,        # tall_\n",
    "    't a l l e r _': 4,    # taller_\n",
    "    'f a s t _': 4,        # fast_\n",
    "}\n",
    "symbols = ['a', 'b', 'c', ...]  # 已有符号\n",
    "```\n",
    "**执行过程**\n",
    "\n",
    "**Step 1: 创建新符号**\n",
    "```Python\n",
    "symbols.append(''.join(('t', 'a')))  # → symbols 增加 'ta'\n",
    "```\n",
    "**Step 2: 合并词项**\n",
    "```Python\n",
    "# 处理 't a l l _'\n",
    "new_token = 't a l l _'.replace('t a', 'ta')  # → 'ta l l _'\n",
    "\n",
    "# 处理 't a l l e r _'\n",
    "new_token = 't a l l e r _'.replace('t a', 'ta')  # → 'ta l l e r _'\n",
    "\n",
    "# 处理 'f a s t _'\n",
    "new_token = 'f a s t _'.replace('t a', 'ta')  # 无 't a'，保持不变\n",
    "```\n",
    "**Step 3: 构建新字典**\n",
    "```Python\n",
    "new_token_freqs = {\n",
    "    'ta l l _': 5,        # 原为 't a l l _'\n",
    "    'ta l l e r _': 4,    # 原为 't a l l e r _'\n",
    "    'f a s t _': 4,       # 未变化\n",
    "}\n",
    "```\n",
    "**为什么这样设计？**\n",
    "1. 空格分隔的重要性<br>\n",
    "字符序列用空格分隔字符（如 't a l l _'），确保只合并相邻字符：\n",
    "```Python\n",
    "# 正确：仅合并相邻的 't a'\n",
    "'t a l l _'.replace('t a', 'ta')  # → 'ta l l _'\n",
    "\n",
    "# 错误：如果用无空格字符串，会错误合并\n",
    "'tall_'.replace('ta', 'ta')  # 会匹配到 'ta'，但无法保证相邻性\n",
    "```\n",
    "2. 保持频率不变<br>\n",
    "合并操作不改变词频，只改变词形：\n",
    "```Python\n",
    "new_token_freqs[new_token] = token_freqs[token]  # 直接复制频率\n",
    "```\n",
    "3. 全局替换<br>\n",
    "replace()会替换所有出现位置：\n",
    "```Python\n",
    "'t a l l e r _'.replace('t a', 'ta')  # 即使出现多次也会被全部替换\n",
    "```\n",
    "**在BPE算法中的位置**\n",
    "\n",
    "**这是 BPE训练循环的核心步骤：**\n",
    "```Python\n",
    "while len(symbols) < vocab_size:\n",
    "    # 1. 统计字符对频率\n",
    "    pair = get_max_freq_pair(token_freqs)\n",
    "    \n",
    "    # 2. 合并最高频对\n",
    "    token_freqs = merge_symbols(pair, token_freqs, symbols)\n",
    "    \n",
    "    # 3. 重复直到达到目标词汇量\n",
    "```\n",
    "**每次迭代：**\n",
    "- 词汇表新增1个符号（如 'ta'）\n",
    "- 词频字典更新为合并后形式\n",
    "- 模型能力增强（能表示更长的子词单元）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877dce88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:35.635554Z",
     "iopub.status.busy": "2023-08-18T06:56:35.634913Z",
     "iopub.status.idle": "2023-08-18T06:56:35.639631Z",
     "shell.execute_reply": "2023-08-18T06:56:35.638892Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def merge_symbols(max_freq_pair, token_freqs, symbols):\n",
    "    # 1. 创建新符号并加入词汇表：将新符号（如 'ta'）添加到BPE词汇表\n",
    "    # ''.join(max_freq_pair)：将字符对元组转为字符串（如('t','a')→'ta'）\n",
    "    symbols.append(''.join(max_freq_pair))\n",
    "    # 2. 初始化新词频字典：存储合并后的词项及其频率\n",
    "    new_token_freqs = dict()\n",
    "    '''\n",
    "    3. 遍历所有词项进行合并\n",
    "    ' '.join(max_freq_pair)：将字符对转为带空格的字符串（如't a'）\n",
    "        token.replace(...)：全局替换所有出现的该字符对\n",
    "            将't a'→'ta'\n",
    "            仅替换连续相邻的字符对\n",
    "    '''\n",
    "    for token, freq in token_freqs.items():\n",
    "        new_token = token.replace(' '.join(max_freq_pair),\n",
    "                                  ''.join(max_freq_pair))\n",
    "        new_token_freqs[new_token] = token_freqs[token]\n",
    "    return new_token_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e888f9",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "| 轮次      | 最高频对            | 新符号       | 合并后的词项示例                       | 词汇表变化    |\n",
    "| ------- | --------------- | --------- | ------------------------------ | -------- |\n",
    "| **#1**  | `('t', 'a')`    | `'ta'`    | `'ta l l _'`, `'ta l l e r _'` | `+ta`    |\n",
    "| **#2**  | `('l', 'l')`    | `'ll'`    | `'ta ll _'`, `'ta ll e r _'`   | `+ll`    |\n",
    "| **#3**  | `('ta', 'll')`  | `'tall'`  | `'tall _'`, `'tall e r _'`     | `+tall`  |\n",
    "| **#4**  | `('e', 'r')`    | `'er'`    | `'tall er _'`, `'fast er _'`   | `+er`    |\n",
    "| **#5**  | `('fast', '_')` | `'fast_'` | ...                            | `+fast_` |\n",
    "| **#6**  | `('tall', '_')` | `'tall_'` | ...                            | `+tall_` |\n",
    "| ...     | ...             | ...       | ...                            | ...      |\n",
    "| **#10** | `('er', '_')`   | `'er_'`   | ...                            | `+er_`   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea95bc7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:35.643247Z",
     "iopub.status.busy": "2023-08-18T06:56:35.642643Z",
     "iopub.status.idle": "2023-08-18T06:56:35.647847Z",
     "shell.execute_reply": "2023-08-18T06:56:35.647061Z"
    },
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并# 1: ('t', 'a')\n",
      "合并# 2: ('ta', 'l')\n",
      "合并# 3: ('tal', 'l')\n",
      "合并# 4: ('f', 'a')\n",
      "合并# 5: ('fa', 's')\n",
      "合并# 6: ('fas', 't')\n",
      "合并# 7: ('e', 'r')\n",
      "合并# 8: ('er', '_')\n",
      "合并# 9: ('tall', '_')\n",
      "合并# 10: ('fast', '_')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. 设定合并次数\n",
    "含义：执行10轮字符对合并\n",
    "结果：词汇表将新增10个子词单元（如'ta','ll','er'等）\n",
    "选择依据：根据目标词汇量或计算资源决定\n",
    "'''\n",
    "num_merges = 10 # 设定合并次数\n",
    "for i in range(num_merges):\n",
    "    '''\n",
    "    2. 找出最高频字符对\n",
    "    调用：统计当前所有相邻字符对的频率\n",
    "    返回：频率最高的字符对元组（如('t','a')）\n",
    "    '''\n",
    "    max_freq_pair = get_max_freq_pair(token_freqs) # 找出当前最高频字符对\n",
    "    '''\n",
    "    3. 合并字符对并更新数据\n",
    "    作用：将所有词项中的该字符对合并为新符号\n",
    "    更新：token_freqs变为合并后的新字典\n",
    "    副作用：symbols列表追加新符号\n",
    "    '''\n",
    "    token_freqs = merge_symbols(max_freq_pair, token_freqs, symbols) # 合并该字符对\n",
    "    '''\n",
    "    4. 打印合并进度\n",
    "    输出示例：合并# 1:('t','a')\n",
    "    调试用途：观察BPE学习过程\n",
    "    '''\n",
    "    print(f'合并# {i+1}:',max_freq_pair) # 打印进度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6d30f",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "在字节对编码的10次迭代之后，我们可以看到列表`symbols`现在又包含10个从其他符号迭代合并而来的符号。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d6459f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:35.651408Z",
     "iopub.status.busy": "2023-08-18T06:56:35.650818Z",
     "iopub.status.idle": "2023-08-18T06:56:35.654893Z",
     "shell.execute_reply": "2023-08-18T06:56:35.654143Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', '[UNK]', 'ta', 'tal', 'tall', 'fa', 'fas', 'fast', 'er', 'er_', 'tall_', 'fast_']\n"
     ]
    }
   ],
   "source": [
    "print(symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70283228",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "对于在词典`raw_token_freqs`的键中指定的同一数据集，作为字节对编码算法的结果，数据集中的每个词现在被子词“fast_”“fast”“er_”“tall_”和“tall”分割。例如，单词“fast er_”和“tall er_”分别被分割为“fast er_”和“tall er_”。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f319afc3",
   "metadata": {},
   "source": [
    "| 代码片段                 | 作用     | 示例输出                                          |\n",
    "| -------------------- | ------ | --------------------------------------------- |\n",
    "| `token_freqs.keys()` | 获取所有词项 | `dict_keys(['t a l l _', ...])`               |\n",
    "| `list(...)`          | 转为列表   | `['t a l l _', 't a l l e r _', 'f a s t _']` |\n",
    "| `print(...)`         | 打印查看   | 显示在控制台，用于监控                                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93120bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:35.658487Z",
     "iopub.status.busy": "2023-08-18T06:56:35.657897Z",
     "iopub.status.idle": "2023-08-18T06:56:35.662020Z",
     "shell.execute_reply": "2023-08-18T06:56:35.661268Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fast_', 'fast er_', 'tall_', 'tall er_']\n"
     ]
    }
   ],
   "source": [
    "print(list(token_freqs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83456139",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "请注意，字节对编码的结果取决于正在使用的数据集。我们还可以使用从一个数据集学习的子词来切分另一个数据集的单词。作为一种贪心方法，下面的`segment_BPE`函数尝试将单词从输入参数`symbols`分成可能最长的子词。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3899dc",
   "metadata": {},
   "source": [
    "**算法流程：**\n",
    "1. 从整词开始：token[0:len(token)]（如 'tallest_'）\n",
    "2. 是否在词汇表：\n",
    "- 是：找到最长子词！添加到结果，移动指针到剩余部分\n",
    "- 否：将 end 减1，尝试更短的子串\n",
    "3. 重复：直到匹配或无法继续\n",
    "**示例：分词 'tallest_'**\n",
    "```Python\n",
    "symbols = ['tall_', 'er_', 't', 'a', 'l', ...]\n",
    "\n",
    "# 尝试1: 'tallest_' ✗ 不在词汇表 → end=7\n",
    "# 尝试2: 'tallest'  ✗ 不在词汇表 → end=6\n",
    "# ...\n",
    "# 尝试6: 'tall'     ✗ 不在词汇表 → end=3\n",
    "# 尝试7: 'tal'      ✗ 不在词汇表 → end=2\n",
    "# 尝试8: 'ta'       ✗ 不在词汇表 → end=1\n",
    "# 尝试9: 't'        ✓ 在词汇表！\n",
    "cur_output = ['t']\n",
    "start = 1, end = 8  # 从位置1重新开始\n",
    "```\n",
    "**算法示例**\n",
    "\n",
    "**输入**\n",
    "```Python\n",
    "tokens = ['tallest_', 'faster_']\n",
    "symbols = ['tall_', 'er_', 't', 'a', 'l', 's', 'f', 'e', 'r', '_']\n",
    "```\n",
    "**分词过程**\n",
    "\n",
    "**'tallest_' 的分词**\n",
    "```python\n",
    "t a l l e s t _\n",
    "↑           ↑\n",
    "start=0    end=8\n",
    "尝试 'tallest_'? ✗\n",
    "尝试 'tallest'?  ✗\n",
    "...\n",
    "尝试 'tall_'?    ✓ 在词汇表！\n",
    "输出: ['tall_']\n",
    "start=4, end=8\n",
    "\n",
    "    e s t _\n",
    "    ↑     ↑\n",
    "尝试 'est_'?    ✗\n",
    "尝试 'est'?     ✗\n",
    "...\n",
    "尝试 'er_'?     ✓ 在词汇表！\n",
    "输出: ['tall_', 'er_']\n",
    "start=6, end=8\n",
    "\n",
    "      t _\n",
    "      ↑ ↑\n",
    "尝试 't_'?      ✗\n",
    "尝试 't'?       ✓ 在词汇表！\n",
    "输出: ['tall_', 'er_', 't']\n",
    "start=7, end=8\n",
    "\n",
    "        _ \n",
    "        ↑\n",
    "尝试 '_'?       ✓ 在词汇表！\n",
    "输出: ['tall_', 'er_', 't', '_']\n",
    "start=8 → 完成！\n",
    "\n",
    "最终结果: 'tall_ er_ t _'\n",
    "```\n",
    "**更优的词汇表**\n",
    "\n",
    "如果 symbols 包含 'er' 和 'est_'：\n",
    "```Python\n",
    "'tallest_' →\n",
    "  1. 'tall_' ✓ （最长匹配）\n",
    "  2. 'est_' ✓ （剩余部分）\n",
    "→ 输出: 'tall_ est_'  # 更优分词\n",
    "```\n",
    "**算法特点**\n",
    "\n",
    "**优点**\n",
    "- 确定性：给定词汇表，分词结果唯一\n",
    "- 高效：贪心策略时间复杂度 O(n²)，实际优化后更快\n",
    "- OOV处理：能从未登录词中提取已知子词\n",
    "\n",
    "**缺点**\n",
    "- 非最优：贪心可能错过全局最优（但实践中效果良好）\n",
    "- 词汇表依赖：分词质量取决于 symbols 的覆盖度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e84fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:35.665538Z",
     "iopub.status.busy": "2023-08-18T06:56:35.664918Z",
     "iopub.status.idle": "2023-08-18T06:56:35.670601Z",
     "shell.execute_reply": "2023-08-18T06:56:35.669830Z"
    },
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def segment_BPE(tokens, symbols):\n",
    "    # 1. 初始化输出列表：存储所有词元的分割结果\n",
    "    outputs = []\n",
    "    '''\n",
    "    2. 遍历每个词\n",
    "    token：待分词的字符串（如'tallest_'）\n",
    "    start：当前子词的起始索引\n",
    "    end：当前子词的结束索引（尝试长度）\n",
    "    cur_output：该词的分词结果\n",
    "    '''\n",
    "    for token in tokens:\n",
    "        start, end = 0, len(token)\n",
    "        cur_output = []\n",
    "        # 具有符号中可能最长子字的词元段\n",
    "        # 3. 贪心最长匹配循环\n",
    "        while start < len(token) and start < end:\n",
    "            if token[start: end] in symbols:\n",
    "                cur_output.append(token[start: end])\n",
    "                start = end\n",
    "                end = len(token)\n",
    "            else:\n",
    "                end -= 1\n",
    "        # 4. 处理未匹配部分\n",
    "        # 触发条件：循环结束仍有未匹配的字符；处理：标记为[UNK]（未知词）\n",
    "        if start < len(token):\n",
    "            cur_output.append('[UNK]')\n",
    "        # 5. 拼接结果：将分词列表用空格连接：如['tall_','er_']→'tall_ er_'\n",
    "        outputs.append(' '.join(cur_output))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7118c8",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "我们使用列表`symbols`中的子词（从前面提到的数据集学习）来表示另一个数据集的`tokens`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00e7e03a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:35.674172Z",
     "iopub.status.busy": "2023-08-18T06:56:35.673554Z",
     "iopub.status.idle": "2023-08-18T06:56:35.677812Z",
     "shell.execute_reply": "2023-08-18T06:56:35.677058Z"
    },
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tall e s t _', 'fa t t er_']\n"
     ]
    }
   ],
   "source": [
    "tokens = ['tallest_', 'fatter_']\n",
    "print(segment_BPE(tokens, symbols))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
