{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a4901a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 编码器-解码器架构\n",
    "\n",
    "编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17f77c60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:48.406295Z",
     "iopub.status.busy": "2023-08-18T07:05:48.405469Z",
     "iopub.status.idle": "2023-08-18T07:05:49.653322Z",
     "shell.execute_reply": "2023-08-18T07:05:49.651979Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# 继承自 nn.Module，符合PyTorch模型标准。作为抽象基类，不能直接被实例化使用\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        '''\n",
    "        接收任意关键字参数（如vocab_size,embed_size等）\n",
    "        调用父类nn.Module的初始化器，确保参数注册、设备迁移等机制正常工作\n",
    "        super(Encoder, self)获取Encoder类的父类（即nn.Module）\n",
    "        .__init__(**kwargs)调用父类的初始化构造函数\n",
    "        **kwargs将所有关键字参数原样传递给父类\n",
    "        必须调用的原因:\n",
    "        所有PyTorch模型必须继承nn.Module，而nn.Module的__init__方法做了关键初始化:\n",
    "        注册参数：让.parameters()能遍历所有权重\n",
    "        注册子模块：让.to(device)能迁移整个模型到GPU\n",
    "        初始化钩子：设置.train() / .eval()模式切换机制\n",
    "        '''\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        '''\n",
    "        强制子类实现：直接调用会抛出错误\n",
    "        定义接口规范：所有子类必须实现forward方法，接受输入X和可选参数\n",
    "        多态支持：后续EncoderDecoder类可以接收任意Encoder子类实例\n",
    "        在基类中占位，这个方法只是接口定义，不能直接使用，必须由子类提供具体实现\n",
    "        '''\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d0a9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a6471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:49.659889Z",
     "iopub.status.busy": "2023-08-18T07:05:49.659020Z",
     "iopub.status.idle": "2023-08-18T07:05:49.666360Z",
     "shell.execute_reply": "2023-08-18T07:05:49.665230Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1. 继承结构\n",
    "继承 nn.Module，符合PyTorch模型规范\n",
    "抽象基类：不能直接实例化，必须由具体解码器（如Seq2SeqDecoder、TransformerDecoder）实现\n",
    "'''\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本解码器接口\"\"\"\n",
    "    # 2. 初始化方法\n",
    "    def __init__(self, **kwargs):\n",
    "        # 调用父类构造函数，确保参数注册、设备迁移等功能正常\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "    \n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        '''\n",
    "        3. 状态初始化方法\n",
    "        这是解码器特有的接口，用于接收编码器输出并初始化解码器状态：\n",
    "        enc_outputs:编码器的输出（通常是(output, state)元组）\n",
    "        *args: 可选额外参数（如注意力机制的上下文）\n",
    "        '''\n",
    "        raise NotImplementedError\n",
    "    # 4. 前向传播接口\n",
    "    def forward(self, X, state):\n",
    "        '''\n",
    "        X:解码器输入（如目标语言词元，形状(batch,num_steps)）\n",
    "        state:解码器状态（由init_state初始化，会在每个时间步更新）\n",
    "        返回:(output,new_state)\n",
    "        '''\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae87cdc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "合并编码器和解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb0929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:49.671685Z",
     "iopub.status.busy": "2023-08-18T07:05:49.670944Z",
     "iopub.status.idle": "2023-08-18T07:05:49.678831Z",
     "shell.execute_reply": "2023-08-18T07:05:49.677718Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "与Encoder/Decoder类的关系\n",
    "Encoder/Decoder (抽象接口)\n",
    "       ↓\n",
    "Seq2SeqEncoder/Seq2SeqDecoder (具体实现)\n",
    "       ↓\n",
    "EncoderDecoder (组合封装)\n",
    "EncoderDecoder是 \"组合模式\"：持有编码器和解码器实例，协调它们的工作\n",
    "它本身不实现具体逻辑，而是委托给子模块\n",
    "'''\n",
    "# 继承nn.Module，遵循PyTorch模型标准，具体实现类（非抽象类），可直接实例化使用\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        '''\n",
    "        encoder: 任意Encoder子类实例（如 Seq2SeqEncoder）\n",
    "        decoder: 任意Decoder子类实例（如 Seq2SeqDecoder）\n",
    "        注册子模块：将编码器和解码器注册为self的属性，使其参数能被.parameters()捕获，并能随模型一起.to(device)\n",
    "        '''\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    '''\n",
    "    编码阶段：enc_X（源语言序列） →encoder→enc_outputs:通常enc_outputs是元组 (output, state)\n",
    "    状态初始化：enc_outputs→decoder.init_state()→dec_state:将编码器最终状态转换/传递给解码器\n",
    "    解码阶段：dec_X（目标语言序列） +dec_state→decoder→最终输出\n",
    "    *args的作用：透传额外参数（如序列长度、注意力掩码等）给编码器和解码器\n",
    "    '''\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "required_libs": [],
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
